###########################
# RNALig End-to-End App   #
# clean -> features -> BA #
###########################

import streamlit as st
import os, io, tempfile, zipfile
from typing import List
import pandas as pd
import numpy as np
import joblib

# ------------------- Try to import your full feature extractor -------------------
try:
    import Features_RNALig as FR  # make sure file name is exactly Features_RNALig.py
except ImportError as e:
    FR = None
    _feature_import_error = str(e)
else:
    _feature_import_error = None


# ------------------- Helpers: model & args for Features_RNALig -------------------

@st.cache_resource
def load_model_bundle():
    """
    Load RNALig_training_model.pkl from repo root.
    Expected format: {'model': <sklearn model>, 'features': [list_of_feature_names]}
    """
    try:
        with open("RNALig_training_model.pkl", "rb") as f:
            bundle = joblib.load(f)
    except FileNotFoundError:
        st.error("Model file `RNALig_training_model.pkl` not found in the app folder.")
        return None, None
    except Exception as e:
        st.error(f"Failed to load model bundle: {e}")
        return None, None

    if isinstance(bundle, dict) and "model" in bundle:
        model = bundle["model"]
        feat_names = bundle.get("features", None)
        return model, feat_names
    else:
        st.error("Model bundle has unexpected format. Expected a dict with key `'model'` and optional key `'features'`.")
        return None, None


def build_default_args(outdir: str):
    """
    Build a minimal args object with the same defaults as the CLI in Features_RNALig.py
    so we can call FR.process_one_pdb(path, args) directly.
    """
    class Args:
        pass

    args = Args()
    args.outdir = outdir

    # ---- Ligand detection ----
    args.cutoff = 4.0
    args.min_heavy = 8
    args.require_carbon = True
    args.keep_ions = False

    # ---- Interaction metrics ----
    args.vdw_mode = "shell"
    args.vdw_legacy_cutoff = 4.0
    args.hbond_cutoff = 3.5
    args.hydroph_cutoff = 4.5

    # ---- Electrostatics ----
    args.elec_mode = "charged"
    args.elec_targets = "phosphate"
    args.elec_qthr = 0.2
    args.elec_dmin = 3.0
    args.elec_dmax = 10.0
    args.elec_include_negative = False

    # ---- Visualization (off by default for speed) ----
    args.viz_rna = False
    args.viz_ligand = False
    args.viz_complex = False
    args.pocket_cutoff = 5.0
    args.pocket_sasa = 0.05
    args.rna_label_topk = 5

    # these are used inside process_one_pdb when viz_rna / viz_ligand = True
    args.lig_viz_dir = None
    args.rna_viz_dir = None

    return args


def run_feature_extraction(pdb_paths: List[str]):
    """
    Given a list of PDB/mmCIF file paths, run FR.process_one_pdb on each
    and return:
      - df_features: DataFrame of all features
      - cleaned_files: list of paths to *_clean.pdb generated by Features_RNALig
      - outdir: the output directory used for clean PDBs
    """
    if FR is None or not hasattr(FR, "process_one_pdb"):
        raise RuntimeError(
            "Features_RNALig could not be imported or has no process_one_pdb(). "
            "Make sure Features_RNALig.py is in the same folder as app.py and import works."
        )

    outdir = tempfile.mkdtemp(prefix="rnalig_out_")
    args = build_default_args(outdir)

    rows = []
    cleaned_files = []

    for path in pdb_paths:
        base = os.path.basename(path)
        st.write(f"Processing: `{base}` ...")
        row = FR.process_one_pdb(path, args)
        rows.append(row)

        # Features_RNALig writes a clean subset file: <basename>_clean.pdb  into args.outdir
        clean_name = os.path.splitext(base)[0] + "_clean.pdb"
        clean_path = os.path.join(outdir, clean_name)
        if os.path.exists(clean_path):
            cleaned_files.append(clean_path)

    df_features = pd.DataFrame(rows)
    # Ensure PDB_ID is first column if present, for clarity
    if "PDB_ID" in df_features.columns:
        cols = ["PDB_ID"] + [c for c in df_features.columns if c != "PDB_ID"]
        df_features = df_features[cols]

    return df_features, cleaned_files, outdir


def predict_binding_affinity(df_features: pd.DataFrame):
    """
    Use RNALig_training_model.pkl to predict binding affinity from computed features.
    Returns:
      - df_pred_only: PDB_ID + predicted affinity
      - df_combined: df_features with an extra prediction column
    """
    model, feat_names = load_model_bundle()
    if model is None:
        return None, None

    # Find an ID column for reporting
    id_col = None
    for c in df_features.columns:
        if "pdb" in c.lower():
            id_col = c
            break
    if id_col is None:
        for cand in ("id", "pdb_id", "name", "file", "filename"):
            if cand in [c.lower() for c in df_features.columns]:
                # Map back to actual column name with same lower()
                id_col = next(c for c in df_features.columns if c.lower() == cand)
                break

    # numeric features only
    numeric = df_features.select_dtypes(include=[np.number]).copy()

    if feat_names:
        # ensure all features exist; if missing, fill with NaN
        for f in feat_names:
            if f not in numeric.columns:
                numeric[f] = np.nan
        X = numeric[feat_names].astype(float)
    else:
        X = numeric

    # fill NaNs with median per column
    X = X.fillna(X.median())

    y_pred = model.predict(X)

    if id_col is not None:
        df_pred_only = pd.DataFrame(
            {
                "PDB_ID": df_features[id_col],
                "Predicted_binding_affinity_kcal_mol": y_pred,
            }
        )
    else:
        df_pred_only = pd.DataFrame(
            {
                "Index": np.arange(len(df_features)),
                "Predicted_binding_affinity_kcal_mol": y_pred,
            }
        )

    df_combined = df_features.copy()
    df_combined["Predicted_binding_affinity_kcal_mol"] = y_pred

    return df_pred_only, df_combined


# ------------------- Streamlit UI -------------------

def main():
    st.set_page_config(page_title="RNALig Docker â€” End-to-End", layout="wide")
    st.title("ðŸ§¬ RNALig Docker â€” RNAâ€“Ligand Binding Affinity Pipeline")

    st.markdown(
        """
This app performs the **full pipeline in one go**:

1. Take raw **RNAâ€“ligand PDB/mmCIF** structures  
2. Use your **RNALig feature extractor** (`Features_RNALig.py`)  
3. Use your trained **Random Forest model** (`RNALig_training_model.pkl`)  
4. Output:
   - Cleaned complex files (`*_clean.pdb`)  
   - Full feature table  
   - Predicted binding affinities  
        """
    )

    # Warn if feature extractor is not importable
    if FR is None:
        st.error(
            "Could not import `Features_RNALig`. "
            "Please make sure `Features_RNALig.py` is in the same folder as `app.py` "
            "and that all its dependencies (freesasa, rdkit, RNA, etc.) are installed."
        )
        if _feature_import_error:
            with st.expander("Import error details"):
                st.code(_feature_import_error)
        return

    st.subheader("Choose input mode")

    mode = st.radio(
        "Input options:",
        (
            "Option 1: Upload up to 5 PDB/mmCIF files",
            "Option 2: Upload one ZIP containing many PDB/mmCIF files",
        ),
    )

    pdb_paths: List[str] = []

    if mode.startswith("Option 1"):
        uploaded_files = st.file_uploader(
            "Upload PDB or mmCIF files",
            type=["pdb", "cif", "mmcif"],
            accept_multiple_files=True,
            help="You can upload up to 5 files here.",
        )
        if uploaded_files:
            if len(uploaded_files) > 5:
                st.warning(
                    f"You uploaded {len(uploaded_files)} files. "
                    f"Only the first 5 will be processed."
                )
                uploaded_files = uploaded_files[:5]

            # Save to temp directory
            tmp_in = tempfile.mkdtemp(prefix="rnalig_in_")
            for up in uploaded_files:
                out_path = os.path.join(tmp_in, up.name)
                with open(out_path, "wb") as f:
                    f.write(up.getbuffer())
                pdb_paths.append(out_path)

    else:  # Option 2: ZIP
        zip_file = st.file_uploader(
            "Upload a ZIP file containing PDB/mmCIF files",
            type=["zip"],
            help="The ZIP can contain multiple .pdb/.cif/.mmcif files (even in subfolders).",
        )
        if zip_file is not None:
            tmp_in = tempfile.mkdtemp(prefix="rnalig_zip_")
            zip_path = os.path.join(tmp_in, "input.zip")
            with open(zip_path, "wb") as f:
                f.write(zip_file.getbuffer())

            with zipfile.ZipFile(zip_path, "r") as zf:
                zf.extractall(tmp_in)

            # Collect all PDB/mmCIF files from extracted content
            for root, dirs, files in os.walk(tmp_in):
                for fn in files:
                    if fn.lower().endswith((".pdb", ".cif", ".mmcif")):
                        pdb_paths.append(os.path.join(root, fn))

            if pdb_paths:
                st.info(f"Found {len(pdb_paths)} structure files inside the ZIP.")
            else:
                st.error("No .pdb/.cif/.mmcif files were found in the ZIP.")

    run_button = st.button("ðŸš€ Run full pipeline (clean + features + prediction)")

    if run_button:
        if not pdb_paths:
            st.error("No input structures to process. Please upload files or a ZIP first.")
            return

        with st.spinner("Running feature extraction using Features_RNALig..."):
            try:
                df_features, cleaned_files, outdir = run_feature_extraction(pdb_paths)
            except Exception as e:
                st.error(f"Feature extraction failed: {e}")
                return

        st.success(f"Feature extraction completed for {len(df_features)} structure(s).")

        # Show features preview
        st.subheader("Extracted Features (preview)")
        st.dataframe(df_features.head())

        # Download full features CSV
        feat_csv = df_features.to_csv(index=False).encode("utf-8")
        st.download_button(
            "ðŸ“¥ Download all features as CSV",
            data=feat_csv,
            file_name="RNALig_features.csv",
        )

        # Prepare cleaned PDB ZIP for download
        if cleaned_files:
            buf = io.BytesIO()
            with zipfile.ZipFile(buf, "w", compression=zipfile.ZIP_DEFLATED) as zf:
                for path in cleaned_files:
                    arcname = os.path.basename(path)
                    zf.write(path, arcname=arcname)
            st.download_button(
                "ðŸ“¥ Download cleaned PDBs (.zip)",
                data=buf.getvalue(),
                file_name="RNALig_cleaned_structures.zip",
            )
        else:
            st.warning("No cleaned PDBs found in the output directory.")

        # ---------------------- Prediction step ----------------------
        st.subheader("Predicted Binding Affinity")

        with st.spinner("Running Random Forest model on extracted features..."):
            df_pred_only, df_combined = predict_binding_affinity(df_features)

        if df_pred_only is None or df_combined is None:
            st.error("Prediction step could not be completed due to model issues.")
            return

        st.write("**Predictions (PDB + predicted binding affinity):**")
        st.dataframe(df_pred_only)

        # Download predictions CSV
        pred_csv = df_pred_only.to_csv(index=False).encode("utf-8")
        st.download_button(
            "ðŸ“¥ Download predictions as CSV",
            data=pred_csv,
            file_name="RNALig_predictions_only.csv",
        )

        # Download combined CSV (features + prediction)
        combined_csv = df_combined.to_csv(index=False).encode("utf-8")
        st.download_button(
            "ðŸ“¥ Download combined features + predictions CSV",
            data=combined_csv,
            file_name="RNALig_features_with_predictions.csv",
        )


if __name__ == "__main__":
    main()
